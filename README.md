# Digital-Music-Store-Database-Project
**Project Description** <br/>
This was a final project of _Using SQL for Data Analysis Course_. The project was aimed to analyze the data of the digital music store which is stored in the Chinbook database to understand their customers, employees, media and invoice information. In this project, you must prepare and analyze the data by using your SQL skills, like (joins, subqueries, views, aliases, aggregations, etc.), and sharing the findings as a presentation that explaining the most important insights. I spent almost 5 days on this project, it was useful and challenging. <br/>
<br/>
**Getting Dataset** <br/>
In this project, I used the _Chinbook Database_, that contains 11 tables, each table has a lot of rows and values. You can get the data through the files which I uploaded in this repository. The name of the database is chinbook-db. <br/>
<br/>
**Project Requirements** <br/>
For the this project, I conducted five Tasks: <br/>
1. Creating creative questions about the digital music store data. <br/>
2. Creating SQL queries that answering your questions. <br/>
3. Pulling the data and transform it, to be able to use in spreadsheet softwares, like (Excel). 
4. Using these data to design visualizations describing your answers visually. <br/>
5. Sharing the findings, by building a presentation in which explain what the data you have, and what the insights you explored. <br/>
<br/>

**Project Methodology** <br/> 
To do these complex and long process we need to build a methodology to be as a plan of doing this process. I used the FACT Framework to do this project correctly. The FACT Framework steps are: <br/>
1. Frame the Questions. <br/>
2. Assemble the data. <br/>
3. Calculate the results. <br/>
4. Tell the others. <br/>

**Phase 1:** _Frame the questions_. In this step, I defined 4 questions which need to utilize all the SQL skills to pull their answers from the database. These questions included quantitative variables and qualitative variables. <br/>
**Phase 2:** _Assemble the data_. Doning this task need to the SQL Skills, therefore I assembled the data by creating complex queries which contains joins, aggregations, subqueries, etc. One of the challenges I faced here, is you should think, depend on the way of the database aggregated. So, you should keep the database schema side by side your analyzing process. From my experience, the hardest thing in querying the data, is the fully correct imagining of the level of granulated data. <br/>
**Phase 3:** _Calculate the results_. With SQL, this step is combined with the previous step, all of them in one query. Some of the calculations which I did, is calculating the averages, counting, highest and lowest values. <br/> 
**Phase 4:** _Tell the others_. After querying process, I got the data, so, I transferd these data into Execl to complete the last step of the analyzing process, which is telling the others by making visualizations that provides fully descriping of the results. I used verios types of plots to describ specific case of data. You can browse the visualizations from the uploaded files in the repository. <br/>


**Project Outcomes**


That is all.
